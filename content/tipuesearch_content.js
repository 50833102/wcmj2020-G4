var tipuesearch = {"pages": [{'title': 'AI是甚麼', 'text': '一個新升起的科技產業，是第四次工業革命的核心。 \n ESCP的院長， Andreas Kaplan曾定義AI是: \n "系統正確解釋外部資料，從這些資料中學習，並利用這些知識透過靈活適應實現特定目標和任務的能力" \n \xa0 Artificial Intelligence，人工的智慧， 以計算機模擬人類的學習功能，使它能自主進化、進行更精確的運算。 \n 目前AI的應用範圍已經廣泛倒不是二三十年前能想像的了，本網站將分出六個類別，共十個主題，每個主題皆是一名組員對AI在這塊領域影響的研究或想法。', 'tags': '', 'url': 'AI是甚麼.html'}, {'title': '生活', 'text': 'AI並非遙不可及的，它就在我們的生活中，而且會和我們越來越緊密，本篇以日常的"食、衣、住、行"，帶出這些人工智慧給我們的生活怎麼樣的改變。', 'tags': '', 'url': '生活.html'}, {'title': '食', 'text': '', 'tags': '', 'url': '食.html'}, {'title': '衣', 'text': 'By胡芳芸50833102 \n AI對於服飾這種需要創意和美感的設計業，乍看之下不會有太大威脅或助益，但事實是: 人工智慧顛覆了這項產業各個已有數千或數百年的作業程序。 \n 本篇將分為設計、生產、販售三個階段，簡述AI對服裝產業的影響。 \n 1.設計 \n 設計師的工作其實是理性的評估潮流趨勢、分析市場的需求、再以自己有系統的美學和製造知識設計出一個成品。 \n 創意產業從理工的角度看似雜亂無章，但其中卻有能透過研究歷史、心理學、經濟學能推導出的某些規律，設計師便是在這個規律中尋求解答: 今年流行甚麼顏色?哪種款式?什麼布料?……等等問題。 \n 而AI出現了。 \n 喜好和流行變成能量化的數據，打個比方，釘圖收集網站Pinterest，如果兩個人在同樣時間註冊這個網站，最初的界面都是差不多的，接著我們過一周的時間，對比兩個帳號，頁面會完全不同。 \n \n \n 同時，出現符合個人喜好圖片的頻率也越來越高，我們可以得知，AI已經有給出符合我們喜好和需求圖片的能力。 \n 那麼具備類似這種大數據能力的人工智能就能透過搜尋資料和服裝公司提供的引導得出符合(或至少接近)時下流行資訊。 \n 再來的步驟也是差不多的概念，讓AI自己去學習如何畫出一個設計圖，一份能提供布料、色號、尺寸的設計圖。 \n 也許這項技術尚不成熟，但已經展現了它的強大和便利，以下影片是bbc在倫敦時尚學院的採訪。 \n https://www.youtube.com/watch?v=0zsm-r3Zik4 \n \n 2.生產 \n 人力資源投入高的成衣產業一直至現代時尚最重要也最被詬病的一塊。 \n 層出不窮的剝削、過勞和中毒是攤在陽光下的陰暗面。 \n 但長久以來，過去的機械對布料絲線這種柔軟的材質無法好好控制，所以就只能用成本便宜的勞工來補足大量的作業需求，人力資源較便宜東南亞有許多國家倚賴服裝品牌在當地建的成衣廠，某些國家的紡織業出口產值甚至一度超過總出口產值的一半。 \n 而在AI技術的加持下，機械如今已經學會縫紉、裁切、打皺褶等等技術，三個人的工作，一台機器能在更短的時間內完成，那麼人力資源需求呢? \n JUHA的老闆給出了回答: \n "訓練過一天，囚犯就能在監獄中的生產線工作了，算做勞動時數。" \n https://www.youtube.com/watch?v=OsSDI8wWAyQ&t=5s \n \n 3.販售 \n 基於網路販售的進化是早已有目共睹的，我們這裡以實體店面為例。 \n https://www.youtube.com/watch?v=CfNtZWIOxX4&t=1s', 'tags': '', 'url': '衣.html'}, {'title': '住', 'text': 'By張仲恩50833139 \n AI 與居住 _ \n 人工智慧技術飛速發展，賦能了智能家居。雖然智能家居逐漸滲透我們的日常生活，但遠未達到大範圍普及使用與「真」智能的程度。消費者不再滿足於傳統的智能家居體驗，正在追求更便捷、富有個性化的智能家庭生活。 \n 利用綜合布線技術、網絡通信技術、 安全防範技術、自動控制技術、音視頻技術將家居生活有關的設施集成，構建高效的住宅設施與家庭日程事務的管理系統，提升家居安全性、便利性、舒適性、藝術性，並實現環保節能的居住環境。 \n 原文網址： https://kknews.cc/tech/mq5qjnz.html \n \n', 'tags': '', 'url': '住.html'}, {'title': '行', 'text': 'By萬興嶸50833105 \n AI與交通的結合 \n 尖峰時間塞車，是都會區不可承受之重，而這樣的問題其實可以用 AI 來解決。由科技部補助的台大人工智慧中心與義隆電子提出「城市車流解決方案」，監控車流並彈性調整交通號誌，改善了 62% 的堵車狀況，不僅降低交通事故，還能節省 10  分鐘的通勤時間。 \n 義隆電子旗下一碩科技提供硬體，搭配台大人工智慧中心的軟體研發所共同推出的解決方案，是將 360 度魚眼相機設置於路口，將所搜集的數據匯入雲端分析，運算最合適的紅綠燈秒數來調節車流。 \n 而業界出題，學界解題也讓這次的合作，有了不錯的成績。以竹北到竹科的實際應用為例，原本該路段行車時間為 16 分鐘，透過「城市車流解決方案」方案後減少至 6 分鐘，節省 10  分鐘的通勤時間，改善幅度達 62 ％，而交通事故從平均每個月 9.5 件降至 8 件。而該方案除了將在台南、高雄、台中、台北、桃園、嘉義等城市落地，目前也已進軍菲律賓宿霧，泰國交通部也規劃引進。 \n 設置於路口的「 360 度魚眼鏡頭」，將收集的車輛數據回傳雲端分析，並彈性調整交通號誌，紓解車流。現有的交通監測工具中，攝影機多半無法做到對車輛自動且精準的計算，而路口若要做到全景監測，得架上多部攝影機，多畫面的整合將會是個問題。 \n 而一碩科技所開發出的魚眼攝影機及校正晶片，搭載 AI 影像辨識技術，將每個路口的轉向車流統整之後，建立出車流的真實模型，解決難以監測的痛點。另外 360 度全景魚眼搭載同集團義晶科技所開發的 360 度全景魚眼修正晶片，將 360 度的影片解碼，降低對電腦運能算力的需求，也因此監控單位的電腦，能負荷數百個鏡頭回傳的畫面，現在一碩已在新竹 400 個路口裝設魚眼鏡頭。 \n \xa0 \n AI與交通工具的結合 \n 卷積類神經網路 \xa0 \n 在深度學習的架構中，卷積類神經網路（ convolutional neural network, CNN ）是相當受歡迎的一個架構。 1989 年由 LeCun 等人提出的 CNN 架構，在手寫辨識分類或人臉辨識方面都有不錯的準確度。近年來，隨著 CPU 效能的提升與繪圖晶片平行化技術的發展，讓具高複雜度、費時的深度學習演算法在即時應用上露出曙光，透過繪圖晶片可讓訓練模組與測試的時間大幅縮短。伴隨著得以取得多樣的影像資料庫， CNN  可觸及更多在照片與影片上的應用。例如近來接續發表的 AlexNet 、 ZF-Net 、 VGG Net 、 GoogLeNet 等，在精確度與效能上都有所改善，甚至在有些情況中可以超越人眼可辨識的範圍。 \n 在影像上的技術發展 \xa0 \n 深度學習在影像應用上正蓬勃發展，從物件分類、物件偵測、物件追蹤、行為分析至反應決策，無一不朝向提高準確度和效能的方向發展。以下介紹近年來在處理物件分類與物件辨識方向熱門的 CNN 網路架構與改進。 \n 物件分類 \n \xa0物件分類是分析一張照片中包含的物件種類，主要是先使用 convolutional layer 進行特徵擷取，再經由 fully- connected layer 合併特徵進行判斷。而在深度學習網路優劣評比中， ILSVRC  （ ImageNet Large Scale Visual RecognitionCompetition ）是一種標竿排名比賽，方便研究者評估與比較物件偵測以及影像分類演算法。以下是幾個著名影像物件分類的網路架構： \xa0 \n LeNet─這是首先成功的 CNN 架構，由 LeCun 在 1990 年提出，見長於辨識數字和英文字母。 \n AlexNet─第一個讓 CNN 網路架構開始在電腦視覺中蓬勃發展的網路，由 Alex Krizhevsky 、 Ilya Sutskever 和 Geoff Hinton 提出，並在 2012 年的 ILSVRC 比賽中比第二名取得了大幅度的領先（ Top 5 error 16 ％，第二名是 26 ％）。 AlexNet 的網路架構類似於 LeNet ，但更深、更大，並且開始使用多個層疊的 convolutional layer ，然後再連接 pooling layer ，有別於以往一層 convolutional layer 都會馬上連接一層 pooling layer 的架構。 \n ZF-Net─由 Matthew Zeiler 和 Rob Fergus 所提出，並在 2013 年的 ILSVRC 取得優勝。他們提出了一個把 CNN 網路中間的特徵層取出並視覺化的方法，便於分析 CNN 架構不足的地方並加以改進。 ZF-Net 便是基於 AlexNet 的優化，活化 AlexNet 中無用的特徵，以得到更好的特徵擷取和辨識效果。 \n VGGNet─由 Karen Simonyan 和 Andrew Zisserman 提出，最主要的貢獻是證明了 CNN 網路的深度對準確度的影響，愈深的網路提供愈好的準確度。但 VGGNet 的網路架構需要更高的計算複雜度，以及更高的記憶體需求。 \n GoogLeNet─由 Google 提出，在 2014 年的 ILSVRC 中取得優勝。 GoogLeNet 提出了 inception module ，可以同時結合不同 level 的特徵，並可串連不同 scale 下的特徵提取值，讓網路可以更深，同時減少參數（例如 GoogLeNet 使用 400 萬個參數， AlexNet 使用了 6,000 萬個參數，而 VGGNet 更需要 14,000 萬個參數），並擁有更好的辨識效果。 \n ResNet—由 Kaiming He 等人提出，在 2015 年的 ILSVRC 中得到優勝。 ResNet 提出的架構可讓特徵值有捷徑跳至後幾層，讓 CNN 網路得以更深，並大量使用 batch normalization ，是目前最佳技術的 CNN 分類網路架構，但它的計算複雜度也最高。 \n 物件偵測 \xa0 \n 相較於物件分類，物件偵測的挑戰更加艱難，它是在一張影像中，需要同時定位物件的座標，再做出分類。現有技術已從最早期開始的遍數法，也就是把影像中所有可能性都使用 CNN 網路判斷，到後來提出在辨識上能更有效率的物件找尋方式。在評估物件偵測演算法優劣上，一般使用 PASCAL VOC  （ visual object classes ）這個開源的標準資料庫進行測試。以下介紹目前著名的物件偵測技術。 \n Sliding windows─早期較原始的找尋目標方式，先把一張圖片由小到大的視窗，整張影像全部掃過一遍，並擷取掃過的影像，餵進 CNN 網路分類。這個方法簡單，但計算量非常大，不適合即時應用。 \n Region proposal CNN network─這個技術是先對影像進行區域提取，透過演算法把影像切分為可能含有物件的區域，再擷取這些區域，提供給物件分類的 CNN 網路判別。著名的架構有 RCNN 、 Fast-RCNN 、 Faster-RCNN 等。 RCNN 使用 selective search 演算法進行區域提取，經過演算後，可以把一張影像取出許多個有可能的區域。但這演算法過於複雜，並且每個區域中進行 CNN 特徵提取時會重複計算，進而導致效能瓶頸。 \n Fast-RCNN─改良自 RCNN ，加速了 RoI pooling layer ，使得 RoI pooling layer 可以把不同大小的輸入 mapping 到固定大小的層，並且改動 RCNN 的流程，先提取可能區域，然後做特徵提取，再從提取完成的特徵圖進行分類。這技術可以避免 RCNN 中特徵提取重複計算的問題，在保證精確度下提升運算速度。 \n Faster-RCNN─ Faster-RCNN 更進一步使用 region proposal network （ RPN ）取代原先的 selective search ，把可能區域的提取方式內嵌到 CNN 網路中，提供訓練和測試一個 end-to-end 的網路架構。 RPN layer 也改善了原先 selective search 只使用 CPU 運算的問題，把可能區域提取透過繪圖晶片加速。 \n 在 regional proposal CNN network 方面，目前常見的著名網路架構有 ZF+Faster-RCNN 、 VGG16+Faster-RCNN 、 R-ResNet-101+Faster-RCNN 、 PVANet 等，前兩個是使用 ZFNet 和 VGGNet 再加上 Faster-RCNN 架構產生的物件偵測網路。 \n ResNet-101+Faster-RCNN是目前準確度最高的架構，準確率達到 83.8 ％，但整體運算量非常大。 PVANet 則多導入了 C. ReLU module  以及改進了 inception module ，透過分析特徵層的特性，讓計算複雜度下降的同時擁有更好的精準度。在 PASCAL VOC2012  中有 82.5 ％的精準度，但運算量只有 ResNet-101+Faster-RCNN  的約十分之一。 \n 統一偵測─ 不同於 region proposal CNN network ，統一偵測（ unified detection ）對於物件偵測的方式不先提出可能區域再進行分類，而是直接把可能區域提取的方式轉為回歸問題。它透過預先設定好的幾個 bounding box ，利用 CNN 網路進行 bounding box 位置回歸以及可信度判斷，同時進行分類。這方法可大幅提升物件偵測的速度，但對於小的物件以及準確度仍有待改進。以下介紹幾個著名的 unified detection 物件偵測網路： \n You only look once（ YOLO ）─ 如其名，人眼在分別物體時並非先抓取位置再進行判斷，而是看到物體的同時辨識物件。 YOLO 提出了 unified detection 的物件偵測方式，透過預先設定好的 bounding box ，再透過縮放平移去貼近到物件邊緣同時判斷，因而大幅提升速度。但它的準確度尤其是對於較小的物件，表現較差。 \n \xa0Single shot multibox detector─改良自 YOLO 網路架構，它把網路分為兩個結構： feature extraction 和 auxiliary 。 Feature extraction 的部分與一般網路類似，用於特徵提取， auxiliary 則是把提取出的特徵再進一步降低維度，讓最後的 fully-connected layer 同時結合不同維度的特徵，進行 bounding box 回歸和物件分類。相較於 YOLO 只使用單一維度的特徵進行判斷，這種方法可以有更佳的準確度，在 PASCAL VOC 有 82.2 ％的平均準確度。 \n 基於物件偵測的自駕車應用 \xa0 \n 深度學習演算法擁有良好的精準度和穩定性，但伴隨的是較高的計算複雜度。然而這個演算法可以大量地平行化，因此適合利用繪圖晶片加速演算。訓練的策略也是機器學習很重要的一環，且要能夠在嵌入式系統上實現，因此它的網路架構必須設法精簡。自駕車在路上容易遇到的物件有車輛、機車騎士、行人等，鎖定這幾類物件偵測可以降低深度學習的複雜度，使得在同樣的精準度下達到更快的偵測速度。 \n Pascal VOC2007 datasets中包含 20 類物件，如飛機、腳踏車、鳥、船、貓、狗等，自駕車所需的目標只需要偵測汽車、行人與機車騎士。由於機車騎士具備行人特徵，可由行人樣本來偵測，因此只需要從 Pascal VOC2007 datasets 的 20 類樣本中取其中兩類，汽車與行人，當作自駕車系統的一部分訓練樣本，就可訓練出自駕車所需要的模型。 \n 距離偵測與前車防撞警示 \xa0 \n 車距可以利用鏡頭水平拍攝後，藉由鏡頭的高度與焦距推算。在前車防撞警示方面，可利用車前方的相機擷取影像後，透過深度學習物件偵測演算法偵測物件。再由前述車距估算的方法對物件位置分類以及距離估算，並根據自駕車與前方車輛的距離調整安全距離，以避免前方車輛突然緊急煞車，導致自駕車煞車不及而追撞前方車輛。 \n \n 盲區危險警示 \xa0 \n 駕駛人開車時，變換車道或轉向都應注意左右方車輛。而一般車輛在後照鏡的視覺上都有盲點，唯有透過轉頭才能注意到盲點區域的車輛。但在駕駛時轉頭又容易偏離車道或無法注意前方車況，同樣地自駕車也需考慮這問題。解決方案是藉由 AI 深度學習偵測物件，準確地辨識出左右後方區域中的物件，再整合所有資訊，透過鏡頭預先設定的基準線，可以判斷出偵測到的物件是否在需要警示的位置，並以相較於自身車輛的距離而警示。 \n \xa0 應用於路面標線標字偵測 \xa0 \n 由於許多事故都是因汽車駕駛未遵循路上的標線或標字行駛而造成，因此當自駕車行駛在路上時須偵測並理解標線及標字。為使深度學習演算法訓練與偵測更加穩健，通常把路面由俯視轉為鳥瞰角度，建構可應用於馬路標線和標字偵測的模型，讓自駕車遵行路上的標線標字內容，而能安全地行駛在道路上。 \n \n 資訊來源 \n https://scitechvista.nat.gov.tw/c/sTkg.htm \n https://www.bnext.com.tw/article/51602/ai-smart-city-traffic-fisheye \n https://fc.bnext.com.tw/turing-ai-bus/', 'tags': '', 'url': '行.html'}, {'title': '健康', 'text': 'AI在健康方面的貢獻在近年來有顯著的增加， 醫療資源將 更加有效率、更有保障。 \n 配合疫情，本篇另外增加了COVID19的一篇文章，由03號同學整理。 \n \xa0', 'tags': '', 'url': '健康.html'}, {'title': '醫療體系', 'text': 'By廖俊澈50833136 \n \n 由於全球逐漸走向高齡化社會，醫療電子市場持續受到半導體產業的關注。根據市調機構MarketsAndMarkets針對2019年醫療產業所做的調查，該單位認為，醫療科技不斷發展，目前已進展至醫療4.0時代，2019年更將整合大數據與AI智慧分析，輔助診斷檢測進而做到精準醫療，預計2022年全球市場規模可達到79.9億美元，潛在商機可觀。 \n 另外，Forbes的分析資料顯示，到2019年底，在醫療保健領域採用AI技術實踐的應用市場規模將超過17億美元。AI在整個醫療產業中，除了在資料分析領域，包括醫療影像輔助決策、藥物發現與風險分析應用等可看到具體成果，並且在未來215%的生產率之外，其他AI技術支援的互動介面：如語音互動或聊天機器人，將針對老年護理、慢性病管理、醫師助理與線上客服等方向提供市場發展機會。 \n 不僅如此，AI應用在醫療保健的發展關鍵，不僅提高產業生產率與降低營運成本，還需要保護顧客在數位資產中的安全性和隱私，設法創造可信價值，讓顧客願意投入額外預算在此類應用服務中，以維持市場的成長。因此，可以說2019年醫療產業的發展重點就是擁抱AI，並透過AI技術實現更多智慧醫療應用，而AI技術在醫療設備領域的應用也將主要集中在醫學影像、輔助診斷、藥物研發、健康管理、疾病預測等幾大領域。 \n 國外醫療領域對AI技術的應用，以藥物研發為主，而中國則借助醫療影像大數據及影像辨識技術的優勢，大力發展AI醫學影像。AI應用在醫學影像領域，能幫助醫生提高早診率，減少誤診率 \n AI醫療、可穿戴和遠端患者監護醫療設備目前的開發都處於起步階段，這些設備可用於現代醫院、診所及患者家中，旨在更有效地診斷和治療疾病。而相關醫療設備的設計除了上述提到的主處理晶片，還包括低功耗單晶片、微處理器、無線元件、安全元件、觸控元件，以及類比/混合訊號元件等。 \n 而AI在很多領域開始向人們展現其「智慧」，但在醫療這種涉及人命的領域中，AI本身還存在著許多關鍵基礎性與實際應用的問題，如數據的穩定性有待提高、開發演算法的工程師並不懂「醫」等，同時還涉及到醫學倫理等問題。醫生提供的診斷結論是基於經驗、倫理和實踐，但AI目前還不能做到「推理」，這些也是AI應用在醫療健康領域下一步需要解決的問題。 \n \xa0', 'tags': '', 'url': '醫療體系.html'}, {'title': 'COVID-19', 'text': 'By黃昱翔50833103 \n 前言:由於今年武漢肺炎疫情爆發，所以向透過這次的報告探討AI在人類的醫療方面有什麼樣的幫助。 \n ____ \n 美國及中國研究人員今天發布報告指出，他們已研發出一種人工智慧（AI）工具，可以準確預測哪些剛感染2019冠狀病毒疾病（COVID-19，武漢肺炎）的患者會出現嚴重肺疾。 \n 法新社報導，這項AI工具能測出多項指標，這些指標最能有效預測哪些武漢肺炎患者將出現所謂的急性呼吸窘迫症候群（ARDS）。 \n 急性呼吸窘迫症候群是2019冠狀病毒疾病的嚴重併發症，會導致肺部積水，有這項併發症的武漢肺炎患者死亡率大約50%。 \n 研究團隊運用機器學習演算法，分析中國溫州市兩間醫院的53名武漢肺炎患者數據，發現最能準確預測往後會出現重疾的3項特徵變化。 \n 這些特徵變化包括肝臟酵素丙氨酸轉氨酶（Alanine transaminase，ALT）濃度、身體疼痛及血紅素（hemoglobin）濃度。 \n 研究共同作者、紐約大學葛羅斯曼醫學院（NYU Grossman School of Medicine）教授卡菲（Megan Coffee）指出，一旦有效運用這套演算法，將可協助醫生在資源緊繃的醫療系統中，決定照護的優先次序。 \n 武漢肺炎（新型冠狀病毒病，COVID-19）疫情全球擴散，確診病例突破六百萬人，台灣開發出「武漢肺炎胸腔Ｘ光輔助診斷系統」，以AI人工智慧分析Ｘ光片，可精準早先一步找出感染武漢肺炎者，這套獨步全球的「科技防疫」技術，已有英國、歐盟、美國Facebook公司申請使用。 \n 微軟人工智慧前首席研發總監杜奕瑾所創辦的台灣人工智慧實驗室（Taiwan AI Labs），去年底與衛福部合作開發「瘧疾辨識系統」有成，今年三月武漢肺炎擴及歐美國家，全球疫情大爆發之際，由於當時快篩尚在開發階段，檢驗新冠病毒受限於PCR核酸分子檢測，須等待四小時才知結果。 \n 為使檢測武漢肺炎方式多管齊下，行政院副院長陳其邁邀集台灣人工智慧實驗室、政院資安處、疾管署、健保署、台大醫院、台北醫學大學附設醫院等產官學界開會，開發以人工智慧模式協助診斷，讓沒有接觸過確診患者的醫師能透過AI分析Ｘ光片，早一步掌握肺炎患者。 \n 可在確診前 2 到 5 天預警 \n 據指出，肺炎患者若出現病徵，肺部會有纖維化等症狀，明顯與健康民眾、肺結核患者不同。台灣人工智慧實驗室今年將系統建置完成後，共分析健保署提供的一○九件胸部Ｘ光片。 \n 分析發現，可被AI系統判定是武漢肺炎的胸部Ｘ光，早於確診前兩天就拍攝出的有廿七名，早於確診前五天的有四名；「武漢肺炎胸腔Ｘ光輔助診斷系統」可提早預警武漢肺炎確診，降低感染風險，且經台大醫療團隊建議調整後，精準度高達八十九％。截至五月底，國內有台大醫院、北醫附設醫院等四家公私醫學中心申請使用。 \n 精準度 89 ％ 國內 4 醫院設置 \n 因全球疫情嚴峻，包含英國、歐盟、美國臉書公司，都向台灣人工智慧實驗室申請。只要自購一台胸部Ｘ光機，介接這套AI系統，便可輕鬆判斷出武漢肺炎。該診斷系統目前免費提供外國使用，台灣要以「Taiwan Can Help」模式幫助世界，度過武漢肺炎疫情難關。 \n 資料來源 : 中央社報導、自由時報 \n \n \n \n \xa0', 'tags': '', 'url': 'COVID-19.html'}, {'title': '經濟', 'text': '\xa0AI讓我們的生活有如此巨大的改變，當然也就脫不開各種金錢上的競爭和評估，本篇將從經濟的角度切入，說明AI對人類經濟的影響、和它本身的經濟價值。', 'tags': '', 'url': '經濟.html'}, {'title': 'AI的經濟價值', 'text': 'By王信竤50833124 \n 人類之所以能成為地球霸主，關鍵在於人類群體能「大規模」且「彈性」的合作，而這種合作的特質，剛好呼應了經濟學的規模經濟與範疇經濟。 \n 規模經濟的重點就是「複製」，這種過程中所需的技術與生產要素大致相同，惟需加倍投入資金成本與專心經營，此種營運模式，也正是台灣製造業的強項。 \n 範疇經濟則較具挑戰性，隨產品或服務的多樣化，需藉由跨領域整合能力，才能提升各種資源的「綜合成效」，擴大經濟收益。簡單來說，如果缺乏跨系統、跨領域的精密協作，既無法達到成效，也無法實現彈性合作，所以範疇經濟在過去並沒有規模經濟普遍。 \n 當前人工智慧的電腦系統處理大規模且彈性協作的能力，正快速超越人類。只要運用合適的晶片與軟體，再加上大數據，就能跨領域、跨系統協同生產。不像人類因個體條件差異或資訊處理能力不一，會影響分工合作的效率，例如傳統製鞋工序繁複，但現在可用電腦以類似縫紉的方式，一體成形生產「針織鞋」，大幅提升品質和效率，降低人工成本。 \n 其他產業，若能借助人工智慧重新規畫生產線，能將許多過去無法處理的廢物或廢料，再加以利用，甚至在「範疇經濟」的效益上，再增加當前世界潮流的「循環經濟」效益。以電力系統做例子，傳統的核能、燃煤、燃油，都是以線性的封閉系統供應鏈來拓展規模經濟，但當前重點發展方向，則是以太陽能、風力發電等開放系統下的再生能源，結合電動車儲能、智慧建築、智慧社區城市的生活系統，強調範疇經濟彈性與韌性為核心價值的電力經濟發展形態。 \n 人類的合作能力雖然勝過所有其他生物，但是比起電腦系統，人類顯然不具競爭優勢。當前的產業策略是善用更大規模、更有彈性的電腦系統與人工智慧，追求整合性、跨領域、跨系統的創新，取代過去傳統的規模經濟思維，發揮範疇經濟「彈性」的主流價值。 \n 參考資料 :   https://www.hbrtaiwan.com/article_content_AR0008406.html', 'tags': '', 'url': 'AI的經濟價值.html'}, {'title': '對人的影響', 'text': 'By張哲豪50833121 \n 1.人事方面:AI在人類的工作上，享有著可以用比較經濟的方法執行任務而不需要有經驗的專家，可以極大地減少勞務開支和培養費用。 \n \xa0 \n 2.計算方面: 人工智慧應用要求繁重的計算，促進了並行處理和專用集成片的開發。例如:股票。 \n \n 3.文化方面: 語言是思維的表現和工具，思維規律可用語言學方法加以研究，但人的下意識和潛意識往往"只能意會，不可言傳"。由於採用人工智慧技術，綜合應用語法、語義和形式知識表示方法，我們有可能在改善知識的自然語言表示的同時，把知識闡述為適用的人工智慧形式。 \n \n 4.勞務就業問題: 人工智慧在科技和工程中的應用，會使一些人失去介入信息處理活動(如規劃、診斷、理解和決策等)的機會，甚至不得不改變自己的工作方式。 \n \n 訊息來源:   https://kknews.cc/zh-tw/tech/kve45m8.html \n 圖片來源:GOOGLE', 'tags': '', 'url': '對人的影響.html'}, {'title': '環保', 'text': 'By簡訢宸50833135 \n 我覺得人工智慧是第四次工業革命的原動力，而且AI可以帶來很大商機，也可以處理全球環境永續的重大問題。 \n AI運用於氣候變遷包括：智慧農業、營養和糧食系統、能源網絡的優化、無人駕駛及互聯的電動車、氣候和天氣模擬等等。 \n 但AI也有能力加速環境的惡化。隨著AI技術的發展，我們需要更好的理解AI對環境的直接問題，以充分利用AI的全部機會，同時評估潛在風險並制定減輕風險的方法。', 'tags': '', 'url': '環保.html'}, {'title': '娛樂', 'text': 'By江睿祥50833109 \n AIVA 是一個 Ai 公司的產品它共創作兩張專輯， 48 張歌曲，其中包跨了古典樂和交響樂，未來將成為第一個被音樂學會（SACEM）認可的虛擬作曲家，AIVA從閱讀古典音樂巴赫、莫札特、貝多芬等人類作曲家創作。自2019年1月以來，該公司還提供商業產品Music Engine，能夠生成各種風格（搖滾，流行，爵士，幻想，簡陋，簡陋，探戈，20世紀電影，現代電影和中文） \n https://www.aiva.ai/ \n \xa0 \n', 'tags': '', 'url': '娛樂.html'}]};