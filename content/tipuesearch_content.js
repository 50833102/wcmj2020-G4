var tipuesearch = {"pages": [{'title': 'AI是甚麼', 'text': '一個新升起的科技產業，是第四次工業革命的核心。 \n \xa0', 'tags': '', 'url': 'AI是甚麼.html'}, {'title': '生活', 'text': '', 'tags': '', 'url': '生活.html'}, {'title': '食', 'text': '', 'tags': '', 'url': '食.html'}, {'title': '衣', 'text': '', 'tags': '', 'url': '衣.html'}, {'title': '住', 'text': '', 'tags': '', 'url': '住.html'}, {'title': '行', 'text': 'AI與交通的結合 \n 尖峰時間塞車，是都會區不可承受之重，而這樣的問題其實可以用 AI 來解決。由科技部補助的台大人工智慧中心與義隆電子提出「城市車流解決方案」，監控車流並彈性調整交通號誌，改善了 62% 的堵車狀況，不僅降低交通事故，還能節省 10  分鐘的通勤時間。 \n 義隆電子旗下一碩科技提供硬體，搭配台大人工智慧中心的軟體研發所共同推出的解決方案，是將 360 度魚眼相機設置於路口，將所搜集的數據匯入雲端分析，運算最合適的紅綠燈秒數來調節車流。 \n 而業界出題，學界解題也讓這次的合作，有了不錯的成績。以竹北到竹科的實際應用為例，原本該路段行車時間為 16 分鐘，透過「城市車流解決方案」方案後減少至 6 分鐘，節省 10  分鐘的通勤時間，改善幅度達 62 ％，而交通事故從平均每個月 9.5 件降至 8 件。而該方案除了將在台南、高雄、台中、台北、桃園、嘉義等城市落地，目前也已進軍菲律賓宿霧，泰國交通部也規劃引進。 \n 設置於路口的「 360 度魚眼鏡頭」，將收集的車輛數據回傳雲端分析，並彈性調整交通號誌，紓解車流。現有的交通監測工具中，攝影機多半無法做到對車輛自動且精準的計算，而路口若要做到全景監測，得架上多部攝影機，多畫面的整合將會是個問題。 \n 而一碩科技所開發出的魚眼攝影機及校正晶片，搭載 AI 影像辨識技術，將每個路口的轉向車流統整之後，建立出車流的真實模型，解決難以監測的痛點。另外 360 度全景魚眼搭載同集團義晶科技所開發的 360 度全景魚眼修正晶片，將 360 度的影片解碼，降低對電腦運能算力的需求，也因此監控單位的電腦，能負荷數百個鏡頭回傳的畫面，現在一碩已在新竹 400 個路口裝設魚眼鏡頭。 \n \xa0 \n AI與交通工具的結合 \n 卷積類神經網路 \xa0 \n 在深度學習的架構中，卷積類神經網路（ convolutional neural network, CNN ）是相當受歡迎的一個架構。 1989 年由 LeCun 等人提出的 CNN 架構，在手寫辨識分類或人臉辨識方面都有不錯的準確度。近年來，隨著 CPU 效能的提升與繪圖晶片平行化技術的發展，讓具高複雜度、費時的深度學習演算法在即時應用上露出曙光，透過繪圖晶片可讓訓練模組與測試的時間大幅縮短。伴隨著得以取得多樣的影像資料庫， CNN  可觸及更多在照片與影片上的應用。例如近來接續發表的 AlexNet 、 ZF-Net 、 VGG Net 、 GoogLeNet 等，在精確度與效能上都有所改善，甚至在有些情況中可以超越人眼可辨識的範圍。 \n 在影像上的技術發展 \xa0 \n 深度學習在影像應用上正蓬勃發展，從物件分類、物件偵測、物件追蹤、行為分析至反應決策，無一不朝向提高準確度和效能的方向發展。以下介紹近年來在處理物件分類與物件辨識方向熱門的 CNN 網路架構與改進。 \n 物件分類 \n \xa0物件分類是分析一張照片中包含的物件種類，主要是先使用 convolutional layer 進行特徵擷取，再經由 fully- connected layer 合併特徵進行判斷。而在深度學習網路優劣評比中， ILSVRC  （ ImageNet Large Scale Visual RecognitionCompetition ）是一種標竿排名比賽，方便研究者評估與比較物件偵測以及影像分類演算法。以下是幾個著名影像物件分類的網路架構： \xa0 \n LeNet─這是首先成功的 CNN 架構，由 LeCun 在 1990 年提出，見長於辨識數字和英文字母。 \n AlexNet─第一個讓 CNN 網路架構開始在電腦視覺中蓬勃發展的網路，由 Alex Krizhevsky 、 Ilya Sutskever 和 Geoff Hinton 提出，並在 2012 年的 ILSVRC 比賽中比第二名取得了大幅度的領先（ Top 5 error 16 ％，第二名是 26 ％）。 AlexNet 的網路架構類似於 LeNet ，但更深、更大，並且開始使用多個層疊的 convolutional layer ，然後再連接 pooling layer ，有別於以往一層 convolutional layer 都會馬上連接一層 pooling layer 的架構。 \n ZF-Net─由 Matthew Zeiler 和 Rob Fergus 所提出，並在 2013 年的 ILSVRC 取得優勝。他們提出了一個把 CNN 網路中間的特徵層取出並視覺化的方法，便於分析 CNN 架構不足的地方並加以改進。 ZF-Net 便是基於 AlexNet 的優化，活化 AlexNet 中無用的特徵，以得到更好的特徵擷取和辨識效果。 \n VGGNet─由 Karen Simonyan 和 Andrew Zisserman 提出，最主要的貢獻是證明了 CNN 網路的深度對準確度的影響，愈深的網路提供愈好的準確度。但 VGGNet 的網路架構需要更高的計算複雜度，以及更高的記憶體需求。 \n GoogLeNet─由 Google 提出，在 2014 年的 ILSVRC 中取得優勝。 GoogLeNet 提出了 inception module ，可以同時結合不同 level 的特徵，並可串連不同 scale 下的特徵提取值，讓網路可以更深，同時減少參數（例如 GoogLeNet 使用 400 萬個參數， AlexNet 使用了 6,000 萬個參數，而 VGGNet 更需要 14,000 萬個參數），並擁有更好的辨識效果。 \n ResNet—由 Kaiming He 等人提出，在 2015 年的 ILSVRC 中得到優勝。 ResNet 提出的架構可讓特徵值有捷徑跳至後幾層，讓 CNN 網路得以更深，並大量使用 batch normalization ，是目前最佳技術的 CNN 分類網路架構，但它的計算複雜度也最高。 \n 物件偵測 \xa0 \n 相較於物件分類，物件偵測的挑戰更加艱難，它是在一張影像中，需要同時定位物件的座標，再做出分類。現有技術已從最早期開始的遍數法，也就是把影像中所有可能性都使用 CNN 網路判斷，到後來提出在辨識上能更有效率的物件找尋方式。在評估物件偵測演算法優劣上，一般使用 PASCAL VOC  （ visual object classes ）這個開源的標準資料庫進行測試。以下介紹目前著名的物件偵測技術。 \n Sliding windows─早期較原始的找尋目標方式，先把一張圖片由小到大的視窗，整張影像全部掃過一遍，並擷取掃過的影像，餵進 CNN 網路分類。這個方法簡單，但計算量非常大，不適合即時應用。 \n Region proposal CNN network─這個技術是先對影像進行區域提取，透過演算法把影像切分為可能含有物件的區域，再擷取這些區域，提供給物件分類的 CNN 網路判別。著名的架構有 RCNN 、 Fast-RCNN 、 Faster-RCNN 等。 RCNN 使用 selective search 演算法進行區域提取，經過演算後，可以把一張影像取出許多個有可能的區域。但這演算法過於複雜，並且每個區域中進行 CNN 特徵提取時會重複計算，進而導致效能瓶頸。 \n Fast-RCNN─改良自 RCNN ，加速了 RoI pooling layer ，使得 RoI pooling layer 可以把不同大小的輸入 mapping 到固定大小的層，並且改動 RCNN 的流程，先提取可能區域，然後做特徵提取，再從提取完成的特徵圖進行分類。這技術可以避免 RCNN 中特徵提取重複計算的問題，在保證精確度下提升運算速度。 \n Faster-RCNN─ Faster-RCNN 更進一步使用 region proposal network （ RPN ）取代原先的 selective search ，把可能區域的提取方式內嵌到 CNN 網路中，提供訓練和測試一個 end-to-end 的網路架構。 RPN layer 也改善了原先 selective search 只使用 CPU 運算的問題，把可能區域提取透過繪圖晶片加速。 \n 在 regional proposal CNN network 方面，目前常見的著名網路架構有 ZF+Faster-RCNN 、 VGG16+Faster-RCNN 、 R-ResNet-101+Faster-RCNN 、 PVANet 等，前兩個是使用 ZFNet 和 VGGNet 再加上 Faster-RCNN 架構產生的物件偵測網路。 \n ResNet-101+Faster-RCNN是目前準確度最高的架構，準確率達到 83.8 ％，但整體運算量非常大。 PVANet 則多導入了 C. ReLU module  以及改進了 inception module ，透過分析特徵層的特性，讓計算複雜度下降的同時擁有更好的精準度。在 PASCAL VOC2012  中有 82.5 ％的精準度，但運算量只有 ResNet-101+Faster-RCNN  的約十分之一。 \n 統一偵測─ 不同於 region proposal CNN network ，統一偵測（ unified detection ）對於物件偵測的方式不先提出可能區域再進行分類，而是直接把可能區域提取的方式轉為回歸問題。它透過預先設定好的幾個 bounding box ，利用 CNN 網路進行 bounding box 位置回歸以及可信度判斷，同時進行分類。這方法可大幅提升物件偵測的速度，但對於小的物件以及準確度仍有待改進。以下介紹幾個著名的 unified detection 物件偵測網路： \n You only look once（ YOLO ）─ 如其名，人眼在分別物體時並非先抓取位置再進行判斷，而是看到物體的同時辨識物件。 YOLO 提出了 unified detection 的物件偵測方式，透過預先設定好的 bounding box ，再透過縮放平移去貼近到物件邊緣同時判斷，因而大幅提升速度。但它的準確度尤其是對於較小的物件，表現較差。 \n \xa0Single shot multibox detector─改良自 YOLO 網路架構，它把網路分為兩個結構： feature extraction 和 auxiliary 。 Feature extraction 的部分與一般網路類似，用於特徵提取， auxiliary 則是把提取出的特徵再進一步降低維度，讓最後的 fully-connected layer 同時結合不同維度的特徵，進行 bounding box 回歸和物件分類。相較於 YOLO 只使用單一維度的特徵進行判斷，這種方法可以有更佳的準確度，在 PASCAL VOC 有 82.2 ％的平均準確度。 \n 基於物件偵測的自駕車應用 \xa0 \n 深度學習演算法擁有良好的精準度和穩定性，但伴隨的是較高的計算複雜度。然而這個演算法可以大量地平行化，因此適合利用繪圖晶片加速演算。訓練的策略也是機器學習很重要的一環，且要能夠在嵌入式系統上實現，因此它的網路架構必須設法精簡。自駕車在路上容易遇到的物件有車輛、機車騎士、行人等，鎖定這幾類物件偵測可以降低深度學習的複雜度，使得在同樣的精準度下達到更快的偵測速度。 \n Pascal VOC2007 datasets中包含 20 類物件，如飛機、腳踏車、鳥、船、貓、狗等，自駕車所需的目標只需要偵測汽車、行人與機車騎士。由於機車騎士具備行人特徵，可由行人樣本來偵測，因此只需要從 Pascal VOC2007 datasets 的 20 類樣本中取其中兩類，汽車與行人，當作自駕車系統的一部分訓練樣本，就可訓練出自駕車所需要的模型。 \n 距離偵測與前車防撞警示 \xa0 \n 車距可以利用鏡頭水平拍攝後，藉由鏡頭的高度與焦距推算。在前車防撞警示方面，可利用車前方的相機擷取影像後，透過深度學習物件偵測演算法偵測物件。再由前述車距估算的方法對物件位置分類以及距離估算，並根據自駕車與前方車輛的距離調整安全距離，以避免前方車輛突然緊急煞車，導致自駕車煞車不及而追撞前方車輛。 \n \n 盲區危險警示 \xa0 \n 駕駛人開車時，變換車道或轉向都應注意左右方車輛。而一般車輛在後照鏡的視覺上都有盲點，唯有透過轉頭才能注意到盲點區域的車輛。但在駕駛時轉頭又容易偏離車道或無法注意前方車況，同樣地自駕車也需考慮這問題。解決方案是藉由 AI 深度學習偵測物件，準確地辨識出左右後方區域中的物件，再整合所有資訊，透過鏡頭預先設定的基準線，可以判斷出偵測到的物件是否在需要警示的位置，並以相較於自身車輛的距離而警示。 \n \xa0 應用於路面標線標字偵測 \xa0 \n 由於許多事故都是因汽車駕駛未遵循路上的標線或標字行駛而造成，因此當自駕車行駛在路上時須偵測並理解標線及標字。為使深度學習演算法訓練與偵測更加穩健，通常把路面由俯視轉為鳥瞰角度，建構可應用於馬路標線和標字偵測的模型，讓自駕車遵行路上的標線標字內容，而能安全地行駛在道路上。 \n \n 資訊來源 \n https://scitechvista.nat.gov.tw/c/sTkg.htm \n https://www.bnext.com.tw/article/51602/ai-smart-city-traffic-fisheye \n https://fc.bnext.com.tw/turing-ai-bus/', 'tags': '', 'url': '行.html'}, {'title': '健康', 'text': '\xa0 \n', 'tags': '', 'url': '健康.html'}, {'title': '醫療體系', 'text': '\xa0 \n', 'tags': '', 'url': '醫療體系.html'}, {'title': 'COVID-19', 'text': '\xa0 \n', 'tags': '', 'url': 'COVID-19.html'}, {'title': '經濟', 'text': '\xa0 \n', 'tags': '', 'url': '經濟.html'}, {'title': 'AI的價值', 'text': '', 'tags': '', 'url': 'AI的價值.html'}, {'title': '對人的影響', 'text': '1.人事方面:AI在人類的工作上，享有著可以用比較經濟的方法執行任務而不需要有經驗的專家，可以極大地減少勞務開支和培養費用。 \n \xa0 \n 2.計算方面: 人工智慧應用要求繁重的計算，促進了並行處理和專用集成片的開發。例如:股票。 \n \n 3.文化方面: 語言是思維的表現和工具，思維規律可用語言學方法加以研究，但人的下意識和潛意識往往"只能意會，不可言傳"。由於採用人工智慧技術，綜合應用語法、語義和形式知識表示方法，我們有可能在改善知識的自然語言表示的同時，把知識闡述為適用的人工智慧形式。 \n \n 4.勞務就業問題: 人工智慧在科技和工程中的應用，會使一些人失去介入信息處理活動(如規劃、診斷、理解和決策等)的機會，甚至不得不改變自己的工作方式。 \n \n 訊息來源:   https://kknews.cc/zh-tw/tech/kve45m8.html \n 圖片來源:GOOGLE', 'tags': '', 'url': '對人的影響.html'}, {'title': '環保', 'text': '', 'tags': '', 'url': '環保.html'}, {'title': '娛樂', 'text': '', 'tags': '', 'url': '娛樂.html'}]};